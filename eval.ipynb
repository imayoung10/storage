{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, annotation_path, transform=None):\n",
    "        with open(annotation_path, \"r\") as f:\n",
    "            self.annotations = json.load(f)\n",
    "        self.image_dir = image_dir\n",
    "        self.images = {img[\"id\"]: img for img in self.annotations[\"images\"]}\n",
    "        self.annotations = self.annotations[\"annotations\"]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = list(self.images.keys())[index]\n",
    "        img_info = self.images[image_id]\n",
    "        img_path = os.path.join(self.image_dir, img_info[\"file_name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Load ground truth\n",
    "        gt_boxes = [\n",
    "            ann[\"bbox\"] for ann in self.annotations if ann[\"image_id\"] == image_id\n",
    "        ]\n",
    "        gt_labels = [\n",
    "            ann[\"category_id\"] for ann in self.annotations if ann[\"image_id\"] == image_id\n",
    "        ]\n",
    "\n",
    "        gt_boxes = torch.tensor(gt_boxes, dtype=torch.float32)\n",
    "        gt_labels = torch.tensor(gt_labels, dtype=torch.int64)\n",
    "\n",
    "        return image, {\"boxes\": gt_boxes, \"labels\": gt_labels, \"image_id\": image_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area1 + area2 - intersection\n",
    "\n",
    "    return intersection / union if union > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map(predictions, ground_truths, iou_threshold=0.5):\n",
    "    average_precisions = []\n",
    "    for class_id in set(gt[\"label\"] for gt in ground_truths):\n",
    "        # 클래스별 예측 및 정답 필터링\n",
    "        preds = [p for p in predictions if p[\"label\"] == class_id]\n",
    "        gts = [g for g in ground_truths if g[\"label\"] == class_id]\n",
    "\n",
    "        # 매칭 상태 추적\n",
    "        detected = set()\n",
    "\n",
    "        # 정렬 (Confidence 높은 순)\n",
    "        preds.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "        tp = torch.zeros(len(preds), dtype=torch.float32)\n",
    "        fp = torch.zeros(len(preds), dtype=torch.float32)\n",
    "\n",
    "        for pred_idx, pred in enumerate(preds):\n",
    "            best_iou = 0\n",
    "            best_gt_idx = -1\n",
    "\n",
    "            for gt_idx, gt in enumerate(gts):\n",
    "                iou = calculate_iou(torch.tensor(pred[\"bbox\"]), torch.tensor(gt[\"bbox\"]))\n",
    "                if iou > best_iou and gt_idx not in detected:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = gt_idx\n",
    "\n",
    "            if best_iou > iou_threshold:\n",
    "                tp[pred_idx] = 1\n",
    "                detected.add(best_gt_idx)\n",
    "            else:\n",
    "                fp[pred_idx] = 1\n",
    "\n",
    "        # Precision-Recall 계산\n",
    "        tp_cumsum = torch.cumsum(tp, dim=0)\n",
    "        fp_cumsum = torch.cumsum(fp, dim=0)\n",
    "        precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)\n",
    "        recalls = tp_cumsum / len(gts)\n",
    "\n",
    "        # Average Precision 계산\n",
    "        ap = torch.tensor(0.0)\n",
    "        for t in torch.linspace(0, 1, 11):  # Recall 기준점 (0, 0.1, ..., 1)\n",
    "            valid_precisions = precisions[recalls >= t] if any(recalls >= t) else torch.tensor([0.0])\n",
    "            ap += torch.max(valid_precisions)\n",
    "        ap /= 11\n",
    "\n",
    "        average_precisions.append(ap.item())\n",
    "\n",
    "    return torch.tensor(average_precisions).mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),  \n",
    "    transforms.ToTensor(),          \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  \n",
    "                         std=[0.229, 0.224, 0.225])   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_image_dir = \"/nas/user/jieui/LG/YOLOX/datasets/COCO/val2017\"  # COCO 이미지 경로\n",
    "coco_annotation_path = \"/nas/user/jieui/LG/YOLOX/datasets/COCO/annotations/instances_val2017.json\"\n",
    "dataset = CocoDataset(coco_image_dir, coco_annotation_path, transform)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "ground_truths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in tqdm(data_loader):\n",
    "        images = [img.to(device) for img in images]\n",
    "        outputs = model(images)\n",
    "\n",
    "        for output in outputs:\n",
    "            image_id = targets[\"image_id\"].item()\n",
    "\n",
    "            # Ground truth 저장\n",
    "            for i, box in enumerate(targets[\"boxes\"]):\n",
    "                print(targets['labels'])\n",
    "                ground_truths.append({\n",
    "                    \"image_id\": image_id,\n",
    "                    \"bbox\": box.tolist(),\n",
    "                    \"label\": targets[\"labels\"][0][i].item(),\n",
    "                })\n",
    "\n",
    "            # 예측 저장\n",
    "            for i, box in enumerate(output[\"boxes\"]):\n",
    "                predictions.append({\n",
    "                    \"image_id\": image_id,\n",
    "                    \"bbox\": box.tolist(),\n",
    "                    \"label\": output[\"labels\"][i].item(),\n",
    "                    \"score\": output[\"scores\"][i].item(),\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_score = calculate_map(predictions, ground_truths)\n",
    "print(f\"mAP: {map_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
